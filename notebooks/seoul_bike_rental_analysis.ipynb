{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Bike Rental in Seoul"]}, {"cell_type": "markdown", "metadata": {}, "source": ["KATE expects your code to define variables with specific names that correspond to certain things we are interested in.\n", "\n", "KATE will run your notebook from top to bottom and check the latest value of those variables, so make sure you don't overwrite them.\n", "\n", "* Remember to uncomment the line assigning the variable to your answer and don't change the variable or function names.\n", "* Use copies of the original or previous DataFrames to make sure you do not overwrite them by mistake.\n", "\n", "You will find instructions below about how to define each variable.\n", "\n", "Once you're happy with your code, upload your notebook to KATE to check your feedback."]}, {"cell_type": "markdown", "metadata": {}, "source": ["The dataset used in this assignment was collected to help predict the demand for bike rental in Seoul at any given day and time. It can be found in the University of California Irvine [Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Seoul+Bike+Sharing+Demand).\n", "\n", "The goal of this assignment is to preprocess the input variables into a format that makes them most useful for a linear regression model.\n", "\n", "To begin with, let's import the necessary libraries and read in the data:"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "plt.rcParams[\"figure.dpi\"] = 120\n", "\n", "data = pd.read_csv(\"data/seoul_bike_data.csv\") "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Initial data inspection\n", "\n", "Now that we have the dataset loaded in, let's inspect it with the methods `.info()` and `.head()`. \n", "\n", "Note that the variable `Rented Bike Count` is the target variable we are aiming to predict in this assignment."]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": ["data.info()"]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": ["data.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["As we can see, there are a lot of different variables which take very different ranges, very different units, and, accordingly, have very different interpretations."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Categorical vs. Continuous Variables\n", "\n", "We must analyse each variable and decide how to preprocess it. Some variables are given in a discrete format, but it makes sense to make them continuous, and vice-versa. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Q1. Which variable columns are continuous quantities and which are categorical?**\n", "\n", "\n", "Create two lists, `categorical` and `continuous` which contain the column indices for the categorical and continuous fields, respectively."]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "categorical = [0, 4, 11, 12, 13 ]\n", "continuous = [1, 2, 3, 5, 6, 7, 8, 9, 10 ]\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Q2. Transform the `Date` variable to a continuous value.**\n", "\n", "\n", "The `Date` variable could be informative about a trend over time, and can be interpreted as a continuous variable for time. \n", "\n", "Using `.copy()`, create a copy of `data` called `data_date`. \n", "\n", "From `data_date`, create a new variable containing the values of the `Date` column, but converted to a datetime format (using `pd.to_datetime`). Be sure to specify `format=\"%d/%m/%Y\"` otherwise `pandas` may incorrectly parse the dates.\n", "\n", "Next, compute **the number of days** between each of these dates and the reference date `01/01/2017` and assign this to a new column in `data_date` called `DayCount`.\n", "\n", "\n", "Leave the `Date` column unchanged.\n", "\n", "*Hint: use the `pd.to_datetime()` function and subtract the values in the `Date` column from the reference date.*"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "data_date = data.copy()\n", "\n", "# Convert the 'Date' column to datetime format\n", "date_converted = pd.to_datetime(data_date['Date'], format=\"%d/%m/%Y\")\n", "\n", "# Define reference date\n", "reference_date = pd.to_datetime(\"01/01/2017\", format=\"%d/%m/%Y\")\n", "\n", "# Compute number of days between each date and the reference date\n", "data_date['DayCount'] = (date_converted - reference_date).dt.days\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Q3. Create a new DataFrame with the one-hot representation of the season**\n", "\n", "\n", "Categorical variables must be formatted to a one-hot representation to be ready for a linear regression model. Create $4$ new columns with the one-hot representation of the Seasons (`Spring`, `Summer`, `Autumn`, and `Winter`, in this order.)\n", "\n", "Before starting, create a copy of `data_date` called `data_season` using the `.copy()` method.\n", "\n", "*Hint: for each new column we will have rows with values `True` or `False`. To get these values, you can compare the value of the `Seasons` column to that of the new column of interest.*\n", "\n", "*In other words the new columns will look like:*\n", "\n", "...|Seasons|...|Spring|Summer|Autumn|Winter\n", "---|---|---|---|---|---|---\n", "...|Autumn|...|False|False|True|False\n", "...|Spring|...|True|False|False|False"]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "data_season = data_date.copy()\n", "\n", "\n", "# Create one-hot encoded columns for each season\n", "data_season['Spring'] = data_season['Seasons'] == 'Spring'\n", "data_season['Summer'] = data_season['Seasons'] == 'Summer'\n", "data_season['Autumn'] = data_season['Seasons'] == 'Autumn'\n", "data_season['Winter'] = data_season['Seasons'] == 'Winter'\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once you have implemented the above, uncomment and run the cell below:"]}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [], "source": ["data_season.sample(3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Q4. Transform the categorical `Humidity(%)` variable into a continuous quantity.**\n", "\n", "\n", "In some cases variables are given as discrete categories, but are representing ranges of a continuous values, for example the variable `Humidity(%)`.\n", "\n", "Using `.copy()`, create a copy of `data_season` called `data_humidity`. \n", "\n", "Transform the variable `Humidity(%)` to a continuous quantity. Use the mean value of each category as its continuous value (e.g. if a category is \"10%-20%\", replace it with 15).\n", "\n", "If the value of the category is \">70%\", use 85 as its mean value. Similarly, if it is \"<30%\", use 15 as its mean value.\n", "\n", "Keep the same column name.\n", "\n", "*Hint: You may want to use the `df.replace()` method.*"]}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# Create a copy of data_season\n", "data_humidity = data_season.copy()\n", "\n", "# Create a mapping from categorical ranges to their mean numeric values\n", "humidity_mapping = {\n", "    \"10%-20%\": 15,\n", "    \"20%-30%\": 25,\n", "    \"30%-70%\": 50,\n", "    \"70%-80%\": 75,\n", "    \"80%-90%\": 85,\n", "    \"<30%\": 15,\n", "    \">70%\": 85,\n", "    # Add any other ranges if present in your data\n", "}\n", "\n", "# Replace the values in the 'Humidity(%)' column using the mapping\n", "data_humidity['Humidity(%)'] = data_humidity['Humidity(%)'].replace(humidity_mapping)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once you have implemented `data_humidity`, uncomment and run the following cell:"]}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [], "source": ["data_humidity[\"Humidity(%)\"].value_counts()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Normalisation"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let us inspect the distribution of the continuous variables.\n", "\n", "Use the method `.describe()` to produce some basic statistics."]}, {"cell_type": "code", "execution_count": 24, "metadata": {}, "outputs": [], "source": ["data.describe()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Q5. Visualize the distribution of continuous variables.**\n", "\n", "\n", "Inspect the histograms of the continuous variables in our data using the `.hist()` method. Assign the plot to a variable called `continuous_fig`.\n", "\n", "Note that since we have only been altering categorical variables so far, you should use the original `data` DataFrame in this question.\n", "\n", "*Hint: use the method `plt.tight_layout()` after calling `.hist()` to create a better arrangement of subplots.*"]}, {"cell_type": "code", "execution_count": 25, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "# Select continuous columns by their index or names\n", "continuous_columns = [\n", "    'Rented Bike Count',\n", "    'Hour',\n", "    'Temperature(\u00b0C)',\n", "    'Wind speed (m/s)',\n", "    'Visibility (10m)',\n", "    'Dew point temperature(\u00b0C)',\n", "    'Solar Radiation (MJ/m2)',\n", "    'Rainfall(mm)',\n", "    'Snowfall (cm)'\n", "]\n", "\n", "# Create histograms for these columns\n", "continuous_fig = data[continuous_columns].hist(\n", "    figsize=(12, 10),      # Set size of the overall figure\n", "    bins=30,               # Number of bins per histogram\n", "    edgecolor='black'      # Optional: makes bars clearer\n", ")\n", "\n", "# Tidy up layout\n", "plt.tight_layout()\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Q6. Convert continuous variables into categorical variables.**\n", "\n", "\n", "Note that in the histograms above, these continuous variables have very distinct distribution profiles. For instance, some variables have a very high frequency for a specific value (e.g. zero Solar Radiation). \n", "\n", "It might be useful to have such distinctive values as additional categorical variables.\n", "\n", "Create a new DataFrame with four additional columns with the binary variables for values that occur particularly often in the variables `Solar Radiation`, `Snowfall`, `Rainfall` and `Visibility`. \n", "Create the new columns called `Zero Solar Radiation`, `Zero Snowfall`, `Zero Rainfall` and `Max Visibility`, in this order. \n", "\n", "For instance, the binary variable `Zero Solar Radiation` will indicate if `Solar Radiation` is _close to_ zero (in this question, if it is smaller than 0.1). The same is true for columns `Zero Snowfall` and `Zero Rainfall`.\n", "\n", "Since the most common `Visibility` value is not zero, the binary variable `Max Visibility` will indicate if `Visibility` is _close to_ its maximum value (i.e. if its value is greater than its max value - 0.1).\n", "\n", "First, however, create a copy of `data_humidity` using the `.copy()` method. Call your new DataFrame `data_binary`."]}, {"cell_type": "code", "execution_count": 26, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# Create a copy of the previous dataframe\n", "data_binary = data_humidity.copy()\n", "\n", "# Create binary columns based on thresholds\n", "data_binary['Zero Solar Radiation'] = data_binary['Solar Radiation (MJ/m2)'] < 0.1\n", "data_binary['Zero Snowfall'] = data_binary['Snowfall (cm)'] < 0.1\n", "data_binary['Zero Rainfall'] = data_binary['Rainfall(mm)'] < 0.1\n", "\n", "# Calculate the maximum value of Visibility\n", "max_visibility = data_binary['Visibility (10m)'].max()\n", "\n", "# Create binary column for maximum visibility\n", "data_binary['Max Visibility'] = data_binary['Visibility (10m)'] > (max_visibility - 0.1)\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once you have created these new columns, uncomment and run the following cell:"]}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [], "source": ["data_binary[\"Zero Solar Radiation\"].value_counts()\n", "# data_binary[\"Zero Snowfall\"].value_counts()\n", "# data_binary[\"Zero Rainfall\"].value_counts()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Q7. Normalise variables.**\n", "\n", "\n", "It is important to ensure that input data are all scaled to the same range. Without this, the model may produce inaccurate predictions. Normalising each input variable can help train the model, allow easier interpretation of the learned parameters, and offer better regularisation.\n", "\n", "Normalise each of the continuous variables in `data` to a *z-scored* DataFrame (such that each column has zero mean and unit variance). Use the transformation:\n", "\n", "$$z = \\frac{x - \\mu}{\\sigma}$$\n", "\n", "Where `x` is the original column values, `\u03bc` is the mean of the column, and `\u03c3` is the standard deviation of the column.\n", "\n", "Save the results in a different DataFrame, `data_z`, and visualise the new distributions using the `.hist()` and `plt.tight_layout()` methods.\n", "\n", "Assign the plot to a variable called `normalise_fig`.\n", "\n", "*Hint: use the `mean()` and `std()` methods for the chosen columns.*"]}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [], "source": ["# We create a new figure to make other figures in the notebook don't get modified\n", "plt.figure()\n", "\n", "# Add your code below\n", "# Create a copy to store z-scored data\n", "data_z = data[continuous_columns].copy()\n", "\n", "# Apply z-score normalization\n", "for col in continuous_columns:\n", "    mean = data[col].mean()\n", "    std = data[col].std()\n", "    data_z[col] = (data[col] - mean) / std\n", "    \n", "# Plot histograms of normalized continuous variables\n", "normalise_fig = data_z[continuous_columns].hist(\n", "    figsize=(12, 10),\n", "    bins=30,\n", "    edgecolor='black'\n", ")\n", "\n", "# Adjust layout\n", "plt.tight_layout()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Advanced discretisation"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Q8. Discretising a circular variable.**\n", "\n", "\n", "Some continuous variables are not actually linear variables, and are not a natural input to a linear model. For example, `Hour` is a circular variable - the values 23 and 1 are actually close together in the day. \n", "\n", "Let us transform `Hour` into discrete categories.  Divide the variable into 5 categories: `Morning` (6-10), `Afternoon` (11-16), `Evening` (17-19), `Night` (20-23), `Early Morning` (0-5).\n", "\n", "For example:\n", "\n", "...|Hour|...|Morning|Afternoon|Evening|Night|Early Morning\n", "---|---|---|---|---|---|---|---\n", "...|1|...|False|False|False|False|True\n", "...|13|...|False|True|False|False|False\n", "\n", "\n", "First, however, create a copy of `data_binary` using the `.copy()` method. Call your new DataFrame `data_time_categories`."]}, {"cell_type": "code", "execution_count": 29, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# Create a copy of data_binary\n", "data_time_categories = data_binary.copy()\n", "\n", "# Create boolean columns for each time-of-day category\n", "data_time_categories['Morning'] = data_time_categories['Hour'].between(6, 10)\n", "data_time_categories['Afternoon'] = data_time_categories['Hour'].between(11, 16)\n", "data_time_categories['Evening'] = data_time_categories['Hour'].between(17, 19)\n", "data_time_categories['Night'] = data_time_categories['Hour'].between(20, 23)\n", "data_time_categories['Early Morning'] = data_time_categories['Hour'].between(0, 5)\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once you have implemented the above question, uncomment and run the following cell:"]}, {"cell_type": "code", "execution_count": 30, "metadata": {}, "outputs": [], "source": ["data_time_categories[\"Morning\"].value_counts()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Q9. Inspecting target variable dependency.**\n", "\n", "\n", "The categories chosen above for `Hour` were rather arbitrary. One more advanced data preprocessing step is to inspect how a given input variable influences the target variable. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's use the `seaborn` library to plot this dependency in detail - how the target variable `Rented Bike Count` depends on `Hour` - with the `sns.violinplot()` method. It shows the distribution of bike rentals for each hour of the day. Assign the output of the plot to a variable called `bike_hour_dependency`. For input data, use the `data` DataFrame."]}, {"cell_type": "code", "execution_count": 31, "metadata": {"scrolled": false}, "outputs": [], "source": ["# We create a new figure to make other figures in the notebook don't get modified\n", "# import seaborn as sns\n", "# import matplotlib.pyplot as plt\n", "\n", "# Create the violin plot showing distribution of bike rentals per hour\n", "bike_hour_dependency = sns.violinplot(x='Hour', y='Rented Bike Count', data=data)\n", "\n", "# Optional: add labels and title for clarity\n", "plt.xlabel('Hour')\n", "plt.ylabel('Rented Bike Count')\n", "plt.title('Distribution of Rented Bike Count by Hour')\n", "\n", "plt.show()\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can see that there is complex relation between the variables. Note that as linear models are only sensitive to the mean correlation between variables (not the full distribution), we can focus on the mean values."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Q10. Calculate the mean `Rented Bike Count` for each hour of the day.**\n", "\n", "\n", "Use the methods `.groupby()` and `.mean()` on the `data` DataFrame, save the result to a variable called `mean_count`, and plot the result using `.plot()`."]}, {"cell_type": "code", "execution_count": 32, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "import matplotlib.pyplot as plt\n", "\n", "# Group by 'Hour' and calculate mean of 'Rented Bike Count'\n", "mean_count = data.groupby('Hour')['Rented Bike Count'].mean()\n", "\n", "# Plot the mean rented bike count by hour\n", "mean_count.plot(kind='line', marker='o')\n", "\n", "# Add labels and title for clarity\n", "plt.xlabel('Hour of Day')\n", "plt.ylabel('Mean Rented Bike Count')\n", "plt.title('Mean Rented Bike Count by Hour')\n", "\n", "plt.grid(True)\n", "plt.show()\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Q11. Discretise nonlinear dependency.**\n", "\n", "\n", "We see in the plot above, a highly nonlinear effect of the variable `Hour` on the mean of the target variable `Rented Bike Count`. A linear model is not sensitive to this and it is a strong indication that discretisation of the variable will help. As above, let's create categorical variables for different ranges of `Hour`, but now taking into account the dependency of the target variable.\n", "\n", "We expect that a category will be more predictive if the target does not vary too much for samples of that category. For instance, the target value is similar for the hours 10, 11, 12 and 13, indicating that the range `10 <= Hour < 14` might have good predictive power for the target.\n", "\n", "Divide `Hour` into five new columns as follows:\n", "\n", "New column name | Data\n", "---|---\n", "Hour Cat 1 | `3 <= Hour < 7`\n", "Hour Cat 2 | `7 <= Hour < 10`\n", "Hour Cat 3 | `10 <= Hour < 14`\n", "Hour Cat 4 | `14 <= Hour < 22`\n", "Hour Cat 5 | `22 <= Hour` or `Hour < 3`\n", " \n", "Which will look like:\n", "\n", "...|Hour|...|Hour Cat 1|Hour Cat 2|Hour Cat 3|Hour Cat 4|Hour Cat 5\n", "---|---|---|---|---|---|---|---\n", "...|2|...|False|False|False|False|True\n", "...|9|...|False|True|False|False|False\n", "\n", "First, create a copy of `data_time_categories` using the `.copy()` method. Call your new DataFrame `final_data`."]}, {"cell_type": "code", "execution_count": 33, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# Create a copy of data_time_categories\n", "final_data = data_time_categories.copy()\n", "\n", "# Define the new hour categories\n", "final_data['Hour Cat 1'] = final_data['Hour'].between(3, 6)  # 3 <= Hour < 7\n", "final_data['Hour Cat 2'] = final_data['Hour'].between(7, 9)  # 7 <= Hour < 10\n", "final_data['Hour Cat 3'] = final_data['Hour'].between(10, 13)  # 10 <= Hour < 14\n", "final_data['Hour Cat 4'] = final_data['Hour'].between(14, 21)  # 14 <= Hour < 22\n", "\n", "# For Hour Cat 5: 22 <= Hour or Hour < 3\n", "final_data['Hour Cat 5'] = (final_data['Hour'] >= 22) | (final_data['Hour'] < 3)\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Notice that in this case an hour-by-hour division may even be reasonable. But on the other hand, too many input variables can lead to overfitting problems."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Evaluating predictions"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Q12. Implement linear regression model.**\n", "\n", "\n", "Create a function with a single argument `cols`, which takes as input a `list` of column names to be used to train the model.\n", "\n", "You will need to assign these columns of the `final_data` DataFrame to a variable (`X`), assign the `Rented Bike Count` column to another variable (`Y`), and then use the `.fit()` method of the `LinearRegression` class to train your model.\n", "\n", "Note that you will have to reshape your `Y` variable using the `.reshape()` method. It is currently an array (`[254, 204, ...]`) but the `LinearRegression` model expects it as an _array of arrays_ (`[[254], [204], ...]`).\n", "\n", "Finally, use the `mean_squared_error` to compute the error. Once computed, return the error as a `float`."]}, {"cell_type": "code", "execution_count": 34, "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LinearRegression\n", "from sklearn.metrics import mean_squared_error\n", "\n", "def prediction_error(cols):\n", "    # Assign feature columns to X (DataFrame)\n", "    X = final_data[cols]\n", "    \n", "    # Assign target variable column to Y (Series)\n", "    Y = final_data['Rented Bike Count']\n", "    \n", "    # Convert Y to 2D numpy array as expected by sklearn\n", "    Y_reshaped = Y.values.reshape(-1, 1)\n", "    \n", "    # Initialize and fit the model\n", "    model = LinearRegression()\n", "    model.fit(X, Y_reshaped)\n", "    \n", "    # Predict target values\n", "    Y_pred = model.predict(X)\n", "    \n", "    # Calculate MSE and return as float\n", "    mse = mean_squared_error(Y_reshaped, Y_pred)\n", "    return float(mse)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Uncomment and run the code below to check your implementation."]}, {"cell_type": "code", "execution_count": 35, "metadata": {}, "outputs": [], "source": ["prediction_error([\"Temperature(\u00b0C)\"])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Q13. Compare performance of different `Hour` representations.**\n", "\n", "\n", "Compare the predictions of our linear model on the original `Hour` variable versus our hand-crafted categorical representations (`Hour Cat 1`, `Hour Cat 2` etc).\n", "\n", "Assign the output of the `prediction_error()` function to two variables:\n", "  1. `model1`: for just the `Hour` variable.\n", "  2. `model2`: for the categorical representations that we created.\n", "\n", "Which model has the better performance? Note that with `mean_squared_error`, a lower error indicates a better fit to the data."]}, {"cell_type": "code", "execution_count": 37, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# Model 1: Using just the original Hour variable\n", "model1 = prediction_error(['Hour'])\n", "\n", "# Model 2: Using the categorical Hour variables\n", "categorical_hour_cols = ['Hour Cat 1', 'Hour Cat 2', 'Hour Cat 3', 'Hour Cat 4', 'Hour Cat 5']\n", "model2 = prediction_error(categorical_hour_cols)\n", "\n", "print(f\"Model 1 (Original Hour) MSE: {model1}\")\n", "print(f\"Model 2 (Categorical Hour) MSE: {model2}\")\n", "\n", "if model2 < model1:\n", "    print(\"Categorical hour representation performs better (lower MSE).\")\n", "else:\n", "    print(\"Original Hour representation performs better (lower MSE).\")\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Q14. Compare the prediction error based on the original variables to the prediction error for variables after preprocessing.**\n", "\n", "1. Save to the variable `full_model_original`, the result of calling `prediction_error()` on the original columns which are suitable for a linear regression model. In this case these are `['Hour', 'Temperature(\u00b0C)', 'Wind speed (m/s)', 'Visibility (10m)', 'Dew point temperature(\u00b0C)', 'Solar Radiation (MJ/m2)', 'Rainfall(mm)', 'Snowfall (cm)']`.\n", "<br><br>\n", "2. Save to the variable `full_model_updated`, the result of calling `prediction_error()` using our processed variables. For `full_model_updated`, include the variables from `full_model_original` that we didn't preprocess (like `Temperature(\u00b0C)`, `Wind speed (m/s)` etc), but where we have processed a variable (like `Hour`), don't include the unprocessed variable."]}, {"cell_type": "code", "execution_count": 41, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# Original columns suitable for linear regression\n", "original_cols = [\n", "    'Hour', \n", "    'Temperature(\u00b0C)', \n", "    'Wind speed (m/s)', \n", "    'Visibility (10m)', \n", "    'Dew point temperature(\u00b0C)', \n", "    'Solar Radiation (MJ/m2)', \n", "    'Rainfall(mm)', \n", "    'Snowfall (cm)'\n", "]\n", "\n", "# Columns after preprocessing:\n", "# - For Hour, use the processed categorical columns (Hour Cat 1 to Hour Cat 5)\n", "# - For other variables, keep as is (assuming they weren't preprocessed)\n", "processed_cols = [\n", "    'Temperature(\u00b0C)', \n", "    'Wind speed (m/s)', \n", "    'Visibility (10m)', \n", "    'Dew point temperature(\u00b0C)', \n", "    'Solar Radiation (MJ/m2)', \n", "    'Rainfall(mm)', \n", "    'Snowfall (cm)',\n", "    'Hour Cat 1', \n", "    'Hour Cat 2', \n", "    'Hour Cat 3', \n", "    'Hour Cat 4', \n", "    'Hour Cat 5'\n", "]\n", "\n", "# Calculate prediction errors\n", "full_model_original = prediction_error(original_cols)\n", "full_model_updated = prediction_error(processed_cols)\n", "\n", "print(f\"Full Model Original MSE: {full_model_original}\")\n", "print(f\"Full Model Updated MSE: {full_model_updated}\")\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.13"}}, "nbformat": 4, "nbformat_minor": 4}